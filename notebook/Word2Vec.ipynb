{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RBqcyqm8oyk",
        "outputId": "f700a805-7ec2-4007-e255-471ef43dc2dc"
      },
      "source": [
        "!pip install Unidecode\n",
        "!pip install gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 241 kB 12.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.2.0\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB_ekNMK7Nkw",
        "outputId": "c50565b5-3627-440b-f689-fb0ac54e7ed7"
      },
      "source": [
        "import re\n",
        "import bs4\n",
        "import string\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "import gensim \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "from unidecode import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiUGqbsse9nV"
      },
      "source": [
        "def preprocess(sentences):\n",
        "\n",
        "  new_sentence = ''\n",
        "  sentences = re.sub(r'<\\s*br\\s*\\/s*>', '', sentences)\n",
        "  sentences = re.sub(r'\\n>', ' ', sentences)\n",
        "  sentences = re.sub(r'\\s+', ' ', sentences)\n",
        "  sentences = re.sub(r'\\.+\\s*', '.', sentences)\n",
        "  sentences = re.sub(r'who\\'ll', 'who will', sentences)\n",
        "  sentences = re.sub(r'[IiyouYousheSHE]\\'ll', 'i will', sentences)\n",
        "  sentences = re.sub(r'[wW]ouldn\\'t', 'would not', sentences)\n",
        "  sentences = re.sub(r'[mM]mustn\\'t', 'must not', sentences)\n",
        "  sentences = re.sub(r'[tT]hat\\'s', 'that is', sentences)\n",
        "  # sentences = re.sub(r'oct', ' ', sentences)\n",
        "  sentences = sentences.replace('.', ' ')\n",
        "\n",
        "  for sentence in sentences:\n",
        "    if sentence.isspace() or sentence.isalpha():\n",
        "      new_sentence += sentence.lower()\n",
        "\n",
        "  stopset = stopwords.words('english') + list(string.punctuation)\n",
        "  corpus = \" \".join([word for word in word_tokenize(new_sentence) if word not in stopset])\n",
        "  cleaned_corpus = unidecode(corpus)\n",
        "\n",
        "  return cleaned_corpus\n",
        "\n",
        "\n",
        "def extract_reuters_news(path_file):\n",
        "\n",
        "  file = open(path_file , 'r').read()\n",
        "  soup = bs4.BeautifulSoup(file)\n",
        "  news = [el.text for el in soup.find_all('reuters')] # replace body with content, otherwise bs4 wont find any body other then main body\n",
        "\n",
        "  return news\n",
        "\n",
        "file_path = Path('/content/drive/MyDrive/Leapfrog_internship/Project 4/reut2-021.sgm')\n",
        "if file_path.exists():\n",
        "  news = extract_reuters_news(file_path)\n",
        "else:\n",
        "  Print('-- There is error while reading the file. --')\n",
        "\n",
        "document = []\n",
        "for i, doc in enumerate(news):\n",
        "  document.append(preprocess(doc))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "AbnO05MX1sik",
        "outputId": "e8bf0b65-20aa-4fb1-e58b-ad0a6e6ac30b"
      },
      "source": [
        "news_dataframe = pd.DataFrame(list(zip(news, document)), columns = ['Initial_corpus','Cleaned_corpus'])\n",
        "news_dataframe.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial_corpus</th>\n",
              "      <th>Cleaned_corpus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n19-OCT-1987 15:37:46.03\\n\\n\\n\\n\\n\\n\\n \\nF \\n...</td>\n",
              "      <td>oct f freute f f bccityfedfinanci cityfed fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n19-OCT-1987 15:35:53.55\\ncrudeship\\nbahraini...</td>\n",
              "      <td>oct crudeship bahrainiranusa freute r f amgulf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n19-OCT-1987 15:34:40.05\\nacq\\n\\n\\n\\n\\n\\n \\nF...</td>\n",
              "      <td>oct acq f freute b f bcccrvideosays ccr video ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n19-OCT-1987 15:32:25.38\\n\\ncanada\\n\\n\\n\\n\\n ...</td>\n",
              "      <td>oct canada e f freute b f bcgmgmcanadaunitm gm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n19-OCT-1987 15:32:11.59\\n\\ncanada\\n\\n\\n\\n\\n ...</td>\n",
              "      <td>oct canada e f freute u f bccanadadevelopmentu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Initial_corpus                                     Cleaned_corpus\n",
              "0  \\n19-OCT-1987 15:37:46.03\\n\\n\\n\\n\\n\\n\\n \\nF \\n...  oct f freute f f bccityfedfinanci cityfed fina...\n",
              "1  \\n19-OCT-1987 15:35:53.55\\ncrudeship\\nbahraini...  oct crudeship bahrainiranusa freute r f amgulf...\n",
              "2  \\n19-OCT-1987 15:34:40.05\\nacq\\n\\n\\n\\n\\n\\n \\nF...  oct acq f freute b f bcccrvideosays ccr video ...\n",
              "3  \\n19-OCT-1987 15:32:25.38\\n\\ncanada\\n\\n\\n\\n\\n ...  oct canada e f freute b f bcgmgmcanadaunitm gm...\n",
              "4  \\n19-OCT-1987 15:32:11.59\\n\\ncanada\\n\\n\\n\\n\\n ...  oct canada e f freute u f bccanadadevelopmentu..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX_sLAZT8fqe"
      },
      "source": [
        "def load_model(file_path):\n",
        "\n",
        "  model_w2v = gensim.models.KeyedVectors.load_word2vec_format(file_path, binary=True)\n",
        "\n",
        "  return model_w2v\n",
        "\n",
        "data_folder = Path(\"/content/drive/MyDrive/Leapfrog_internship/Project 6/\")\n",
        "model_path = documents_dfh = data_folder / \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "\n",
        "model_w2v  = load_model(model_path)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmjNNdGB3TqJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "\n",
        "def get_tokenized_elements():\n",
        "\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(news_dataframe.Cleaned_corpus)\n",
        "  tokenized_documents = tokenizer.texts_to_sequences(news_dataframe.Cleaned_corpus)\n",
        "  tokenized_paded_documents = pad_sequences(tokenized_documents, maxlen=64, padding='post')\n",
        "\n",
        "  return tokenizer, tokenized_paded_documents\n",
        "\n",
        "def get_tfidf_elements():\n",
        "\n",
        "  tfidfvectoriser = TfidfVectorizer(max_features = 3000)\n",
        "  tfidfvectoriser.fit(news_dataframe.Cleaned_corpus)\n",
        "  tfidf_vectors = tfidfvectoriser.transform(news_dataframe.Cleaned_corpus)\n",
        "  tfidf_vectors = tfidf_vectors.toarray()\n",
        "  words = tfidfvectoriser.get_feature_names()\n",
        "\n",
        "  return words, tfidf_vectors\n",
        "\n",
        "def document_word_embeddings():\n",
        "\n",
        "  tokenizer, tokenized_paded_documents = get_tokenized_elements()\n",
        "  vocab_size = len(tokenizer.word_index)+1\n",
        "  embedding_matrix = np.zeros((vocab_size, 300))\n",
        "  for word, i in tokenizer.word_index.items():\n",
        "    if word in model_w2v:\n",
        "      embedding_matrix[i] = model_w2v[word]  \n",
        "  doc_word_embeddings = np.zeros((len(tokenized_paded_documents), 3000, 300))\n",
        "  for i in range(len(tokenized_paded_documents)):\n",
        "      for j in range(len(tokenized_paded_documents[0])):\n",
        "          doc_word_embeddings[i][j] = embedding_matrix[tokenized_paded_documents[i][j]]\n",
        "\n",
        "  return embedding_matrix, doc_word_embeddings\n",
        "\n",
        "def document_embeddings():\n",
        "\n",
        "  tokenizer, tokenized_paded_documents = get_tokenized_elements()\n",
        "  words, tfidf_vectors = get_tfidf_elements()\n",
        "  embedding_matrix, doc_word_embeddings = document_word_embeddings()\n",
        "  documentEmbeddings = np.zeros((len(tokenized_paded_documents), 300))\n",
        "  for i in range(len(doc_word_embeddings)):\n",
        "    for j in range(len(words)):   \n",
        "      documentEmbeddings[i] += embedding_matrix[tokenizer.word_index[words[j]]] * tfidf_vectors[i][j]       \n",
        "  documentEmbeddings = documentEmbeddings / np.sum(tfidf_vectors, axis = 1).reshape(-1, 1)\n",
        "  \n",
        "  return documentEmbeddings\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_FkWo3eJUxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67218c6-e772-4269-93e3-8e29a4e35276"
      },
      "source": [
        "documentEmbeddings = document_embeddings()\n",
        "\n",
        "def most_similar(doc_id, similarity_matrix, matrix):\n",
        "\n",
        "    print (f'Document: {news_dataframe.iloc[doc_id][\"Initial_corpus\"]}')\n",
        "    print ('\\n')\n",
        "    print ('Similar Documents:')\n",
        "    if matrix == 'Cosine Similarity':\n",
        "        similar_ix = np.argsort(similarity_matrix[doc_id])[::-1]\n",
        "    elif matrix == 'Euclidean Distance':\n",
        "        similar_ix = np.argsort(similarity_matrix[doc_id])\n",
        "    for ix in range(5):\n",
        "        if ix == doc_id:\n",
        "            continue\n",
        "        print('\\n')\n",
        "        print (f'Document: {news_dataframe.iloc[ix][\"Initial_corpus\"]}')\n",
        "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
        "\n",
        "pairwise_similarities=cosine_similarity(documentEmbeddings)\n",
        "pairwise_differences=euclidean_distances(documentEmbeddings)\n",
        "\n",
        "most_similar(0,pairwise_similarities,'Cosine Similarity')\n",
        "most_similar(0,pairwise_differences,'Euclidean Distance')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document: \n",
            "19-OCT-1987 15:37:46.03\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "F \n",
            "f2882reute\n",
            "f f BC-CITYFED-FINANCI   10-19 0013\n",
            "\n",
            "******CITYFED FINANCIAL CORP SAYS IT CUT QTRLY DIVIDEND TO ONE CENT FROM 10 CTS/SHR\n",
            "Blah blah blah.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Similar Documents:\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:35:53.55\n",
            "crudeship\n",
            "bahrainiranusa\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "Y \n",
            "f2873reute\n",
            "r f AM-GULF-PLATFORM   10-19 0101\n",
            "\n",
            "HUGE OIL PLATFORMS DOT GULF LIKE BEACONS\n",
            "    By ASHRAF FOUAD\n",
            "    BAHRAIN, Oct 19 - Huge oil platforms dot the Gulf like\n",
            "beacons -- usually lit up like Christmas trees at night.\n",
            "    One of them, sitting astride the Rostam offshore oilfield,\n",
            "was all but blown out of the water by U.S. Warships on Monday.\n",
            "    The Iranian platform, an unsightly mass of steel and\n",
            "concrete, was a three-tier structure rising 200 feet (60\n",
            "metres) above the warm waters of the Gulf until four U.S.\n",
            "Destroyers pumped some 1,000 shells into it.\n",
            "    The U.S. Defense Department said just 10 pct of one section\n",
            "of the structure remained.\n",
            "    U.S. helicopters destroyed three Iranian gunboats after an\n",
            "American helicopter came under fire earlier this month and U.S.\n",
            "forces attacked, seized, and sank an Iranian ship they said had\n",
            "been caught laying mines.\n",
            "    But Iran was not deterred, according to U.S. defense\n",
            "officials, who said Iranian forces used Chinese-made Silkworm\n",
            "missiles to hit a U.S.-owned Liberian-flagged ship on Thursday\n",
            "and the Sea Isle City on Friday.\n",
            "    Both ships were hit in the territorial waters of Kuwait, a\n",
            "key backer of Iraq in its war with Iran.\n",
            "    Henry Schuler, a former U.S. diplomat in the Middle East\n",
            "now with CSIS said Washington had agreed to escort Kuwaiti\n",
            "tankers in order to deter Iranian attacks on shipping.\n",
            "    But he said the deterrence policy had failed and the level\n",
            "of violence and threats to shipping had increased as a result\n",
            "of U.S. intervention and Iran's response.\n",
            "    The attack on the oil platform was the latest example of a\n",
            "U.S. \"tit-for-tat\" policy that gave Iran the initiative, said\n",
            "Harlan Ullman, an ex-career naval officer now with CSIS.\n",
            "    He said with this appraoch America would suffer \"the death\n",
            "of one thousand cuts.\"\n",
            "    But for the United States to grab the initiative\n",
            "militarily, it must take warlike steps such as mining Iran's\n",
            "harbors or blockading the mouth of the Gulf through which its\n",
            "shipping must pass, Schuler said.\n",
            "    He was among those advocating mining as a means of bringing\n",
            "Iran to the neogtiating table. If vital supplies were cut off,\n",
            "Tehran could not continue the war with Iraq.\n",
            "    Ullman said Washington should join Moscow in a diplomatic\n",
            "initiative to end the war and the superpowers should impose an\n",
            "arms embargo against Tehran if it refused to negotiate.\n",
            "    He said the United States should also threaten to mine and\n",
            "blockade Iran if it continued fighting and must press Iraq to\n",
            "acknowledge responsibility for starting the war as part of a\n",
            "settlement.\n",
            "    Iranian and Western diplomats say Iraq started the war by\n",
            "invading Iran's territory in 1980. Iraq blames Iran for the\n",
            "outbreak of hostilities, which have entailed World War I-style\n",
            "infantry attacks resulting in horrific casualties.\n",
            "    Each side has attacked the others' shipping.\n",
            " Reuter\n",
            "\n",
            "\n",
            "Cosine Similarity : 0.4353077212477225\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:34:40.05\n",
            "acq\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "F \n",
            "f2863reute\n",
            "b f BC-CCR-VIDEO-SAYS   10-19 0015\n",
            "\n",
            "******CCR VIDEO SAYST RECEIVED OFFER TO NEGOTIATE A TAKEOVER BY INTERCEP INVESTMENT CORP\n",
            "Blah blah blah.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cosine Similarity : 0.5897458265690827\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:32:25.38\n",
            "\n",
            "canada\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "E F \n",
            "f2855reute\n",
            "b f BC-GM-<GM>-CANADA-UNIT-M   10-19 0096\n",
            "\n",
            "GM <GM> CANADA UNIT MAJOR OFFER ACCEPTED BY UNION\n",
            "    TORONTO, Oct 19 - The Canadian Auto Workers' Union said it\n",
            "accepted an economic offer from the Canadian division of\n",
            "General Motors Corp <GM> in contract negotiations.\n",
            "    But union president Bob White said many local issues at the\n",
            "11 plants in Ontario and Quebec still remained unresolved ahead\n",
            "of Thursday's deadline for a strike by 40,000 workers.\n",
            "    \"It minimizes the possibility of a strike,\" White told\n",
            "reporters.\n",
            "    However, \"if we don't have local agreements settled by\n",
            "Thursday, there will be a strike,\" he said.\n",
            "    The local issues still unresolved involved health care,\n",
            "skilled trades and job classifications, White said.\n",
            "    GM Canada negotiator Rick Curd said he believed a strike\n",
            "would be avoided.\n",
            "    \"Even though there are some tough issues to be resolved\n",
            "we're on the right schedule to meet the target,\" Curd said.\n",
            "    \"I'm very pleased with the state of the negotiations,\" he\n",
            "said.\n",
            "    Union membership meetings have been scheduled for the\n",
            "weekend in case a tentative settlement, said White.\n",
            "    White said the union has also received assurances that a\n",
            "job protection pact negotiated with GM workers in the U.S. does\n",
            "not threaten Canadian jobs.\n",
            "    The economic offer for a three-year pact largely matches\n",
            "agreements at Ford <F> and Chrysler <C> in Canada, which\n",
            "include inflation-indexed payments for future retirees and\n",
            "fixed annual payments for current retirees.\n",
            "    It also gives workers wage increases of three pct\n",
            "immediately and 1.5 pct in each of the second and third years.\n",
            " Reuter\n",
            "\n",
            "\n",
            "Cosine Similarity : 0.5379461540086371\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:32:11.59\n",
            "\n",
            "canada\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "E F \n",
            "f2854reute\n",
            "u f BC-CANADA-DEVELOPMENT-UN   10-19 0092\n",
            "\n",
            "CANADA DEVELOPMENT UNIT <CDC.TO> REFINANCES\n",
            "    SARNIA, Ontario, Oct 19 - Canada Development Corp said its\n",
            "<Polysar Ltd> unit completed a refinancing package worth about\n",
            "830 mln Canadian dlrs.\n",
            "    The company said the financing, which involves 24 banks \n",
            "and four syndicated loans, consists of a 380 mln Canadian dlr\n",
            "revolver, a 200 mln Canadian dlr European medium term loan, a\n",
            "149 mln Canadian dlr revolver and a 100 mln Canadian dlr\n",
            "operating loan.\n",
            "    The company said the refinancing will reduce borrowing\n",
            "costs, in addition to having other benefits.\n",
            " Reuter\n",
            "\n",
            "\n",
            "Cosine Similarity : 0.5482348654602797\n",
            "Document: \n",
            "19-OCT-1987 15:37:46.03\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "F \n",
            "f2882reute\n",
            "f f BC-CITYFED-FINANCI   10-19 0013\n",
            "\n",
            "******CITYFED FINANCIAL CORP SAYS IT CUT QTRLY DIVIDEND TO ONE CENT FROM 10 CTS/SHR\n",
            "Blah blah blah.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Similar Documents:\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:35:53.55\n",
            "crudeship\n",
            "bahrainiranusa\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "Y \n",
            "f2873reute\n",
            "r f AM-GULF-PLATFORM   10-19 0101\n",
            "\n",
            "HUGE OIL PLATFORMS DOT GULF LIKE BEACONS\n",
            "    By ASHRAF FOUAD\n",
            "    BAHRAIN, Oct 19 - Huge oil platforms dot the Gulf like\n",
            "beacons -- usually lit up like Christmas trees at night.\n",
            "    One of them, sitting astride the Rostam offshore oilfield,\n",
            "was all but blown out of the water by U.S. Warships on Monday.\n",
            "    The Iranian platform, an unsightly mass of steel and\n",
            "concrete, was a three-tier structure rising 200 feet (60\n",
            "metres) above the warm waters of the Gulf until four U.S.\n",
            "Destroyers pumped some 1,000 shells into it.\n",
            "    The U.S. Defense Department said just 10 pct of one section\n",
            "of the structure remained.\n",
            "    U.S. helicopters destroyed three Iranian gunboats after an\n",
            "American helicopter came under fire earlier this month and U.S.\n",
            "forces attacked, seized, and sank an Iranian ship they said had\n",
            "been caught laying mines.\n",
            "    But Iran was not deterred, according to U.S. defense\n",
            "officials, who said Iranian forces used Chinese-made Silkworm\n",
            "missiles to hit a U.S.-owned Liberian-flagged ship on Thursday\n",
            "and the Sea Isle City on Friday.\n",
            "    Both ships were hit in the territorial waters of Kuwait, a\n",
            "key backer of Iraq in its war with Iran.\n",
            "    Henry Schuler, a former U.S. diplomat in the Middle East\n",
            "now with CSIS said Washington had agreed to escort Kuwaiti\n",
            "tankers in order to deter Iranian attacks on shipping.\n",
            "    But he said the deterrence policy had failed and the level\n",
            "of violence and threats to shipping had increased as a result\n",
            "of U.S. intervention and Iran's response.\n",
            "    The attack on the oil platform was the latest example of a\n",
            "U.S. \"tit-for-tat\" policy that gave Iran the initiative, said\n",
            "Harlan Ullman, an ex-career naval officer now with CSIS.\n",
            "    He said with this appraoch America would suffer \"the death\n",
            "of one thousand cuts.\"\n",
            "    But for the United States to grab the initiative\n",
            "militarily, it must take warlike steps such as mining Iran's\n",
            "harbors or blockading the mouth of the Gulf through which its\n",
            "shipping must pass, Schuler said.\n",
            "    He was among those advocating mining as a means of bringing\n",
            "Iran to the neogtiating table. If vital supplies were cut off,\n",
            "Tehran could not continue the war with Iraq.\n",
            "    Ullman said Washington should join Moscow in a diplomatic\n",
            "initiative to end the war and the superpowers should impose an\n",
            "arms embargo against Tehran if it refused to negotiate.\n",
            "    He said the United States should also threaten to mine and\n",
            "blockade Iran if it continued fighting and must press Iraq to\n",
            "acknowledge responsibility for starting the war as part of a\n",
            "settlement.\n",
            "    Iranian and Western diplomats say Iraq started the war by\n",
            "invading Iran's territory in 1980. Iraq blames Iran for the\n",
            "outbreak of hostilities, which have entailed World War I-style\n",
            "infantry attacks resulting in horrific casualties.\n",
            "    Each side has attacked the others' shipping.\n",
            " Reuter\n",
            "\n",
            "\n",
            "Euclidean Distance : 1.258671109869826\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:34:40.05\n",
            "acq\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "F \n",
            "f2863reute\n",
            "b f BC-CCR-VIDEO-SAYS   10-19 0015\n",
            "\n",
            "******CCR VIDEO SAYST RECEIVED OFFER TO NEGOTIATE A TAKEOVER BY INTERCEP INVESTMENT CORP\n",
            "Blah blah blah.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Euclidean Distance : 1.1292650247848424\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:32:25.38\n",
            "\n",
            "canada\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "E F \n",
            "f2855reute\n",
            "b f BC-GM-<GM>-CANADA-UNIT-M   10-19 0096\n",
            "\n",
            "GM <GM> CANADA UNIT MAJOR OFFER ACCEPTED BY UNION\n",
            "    TORONTO, Oct 19 - The Canadian Auto Workers' Union said it\n",
            "accepted an economic offer from the Canadian division of\n",
            "General Motors Corp <GM> in contract negotiations.\n",
            "    But union president Bob White said many local issues at the\n",
            "11 plants in Ontario and Quebec still remained unresolved ahead\n",
            "of Thursday's deadline for a strike by 40,000 workers.\n",
            "    \"It minimizes the possibility of a strike,\" White told\n",
            "reporters.\n",
            "    However, \"if we don't have local agreements settled by\n",
            "Thursday, there will be a strike,\" he said.\n",
            "    The local issues still unresolved involved health care,\n",
            "skilled trades and job classifications, White said.\n",
            "    GM Canada negotiator Rick Curd said he believed a strike\n",
            "would be avoided.\n",
            "    \"Even though there are some tough issues to be resolved\n",
            "we're on the right schedule to meet the target,\" Curd said.\n",
            "    \"I'm very pleased with the state of the negotiations,\" he\n",
            "said.\n",
            "    Union membership meetings have been scheduled for the\n",
            "weekend in case a tentative settlement, said White.\n",
            "    White said the union has also received assurances that a\n",
            "job protection pact negotiated with GM workers in the U.S. does\n",
            "not threaten Canadian jobs.\n",
            "    The economic offer for a three-year pact largely matches\n",
            "agreements at Ford <F> and Chrysler <C> in Canada, which\n",
            "include inflation-indexed payments for future retirees and\n",
            "fixed annual payments for current retirees.\n",
            "    It also gives workers wage increases of three pct\n",
            "immediately and 1.5 pct in each of the second and third years.\n",
            " Reuter\n",
            "\n",
            "\n",
            "Euclidean Distance : 1.1696872952455923\n",
            "\n",
            "\n",
            "Document: \n",
            "19-OCT-1987 15:32:11.59\n",
            "\n",
            "canada\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "E F \n",
            "f2854reute\n",
            "u f BC-CANADA-DEVELOPMENT-UN   10-19 0092\n",
            "\n",
            "CANADA DEVELOPMENT UNIT <CDC.TO> REFINANCES\n",
            "    SARNIA, Ontario, Oct 19 - Canada Development Corp said its\n",
            "<Polysar Ltd> unit completed a refinancing package worth about\n",
            "830 mln Canadian dlrs.\n",
            "    The company said the financing, which involves 24 banks \n",
            "and four syndicated loans, consists of a 380 mln Canadian dlr\n",
            "revolver, a 200 mln Canadian dlr European medium term loan, a\n",
            "149 mln Canadian dlr revolver and a 100 mln Canadian dlr\n",
            "operating loan.\n",
            "    The company said the refinancing will reduce borrowing\n",
            "costs, in addition to having other benefits.\n",
            " Reuter\n",
            "\n",
            "\n",
            "Euclidean Distance : 1.3061155781587919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkrPIPFTNVaU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}